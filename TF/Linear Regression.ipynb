{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# This is the basic shape for an inference model code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First initialize variables/model parameters\n",
    "W = tf.Variable(tf.zeros([2, 1]), name=\"weights\")\n",
    "b = tf.Variable(0., name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the training loop operations\n",
    "def inputs():\n",
    "    # read/generate input training data X and expected outputs Y\n",
    "    weight_age = [\n",
    "        [84, 46], [73, 20], [65, 52], [70, 30], [76, 57], [69, 25], [63, 28], [72, 36], [79, 57], [75, 44],\n",
    "        [27, 24], [89, 31], [65, 52], [57, 23], [59, 60], [69, 48], [60, 34], [79, 51], [75, 50], [82, 34]]\n",
    "    blood_fat_content = [354, 190, 405, 263, 451, 302, 288, 385, 402, 365,\n",
    "                         209, 290, 346, 254, 395, 434, 220, 374, 308, 220]\n",
    "    return tf.to_float(weight_age), tf.to_float(blood_fat_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(X):\n",
    "    # compute inference model over data X and return the result\n",
    "    return tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(X, Y):\n",
    "    # compute loss over training data X and expected outputs Y\n",
    "    Y_predicted = inference(X)\n",
    "    return tf.reduce_sum(tf.squared_difference(Y, Y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(total_loss):\n",
    "    # train / adjust model parameters according to computed total loss\n",
    "    learning_rate = 0.0000001\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(sess, X, Y):\n",
    "    # evaluate the resulting trained model\n",
    "    print(sess.run(inference([[80., 25.]]))) # ~ 303\n",
    "    print(sess.run(inference([[65., 25.]]))) # ~ 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a saver.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Launch the graph in a session, setup boilerplate\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    initial_step = 0\n",
    "    # verify if we don't have a checkpoint saved already\n",
    "    checkpoint = tf.train.get_checkpoint_state(os.path.dirname(os.path.realpath('__file__')))\n",
    "    if checkpoint and checkpoint.model_checkpoint_path:\n",
    "        # Restores from checkpoint\n",
    "        saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "        initial_step = int(checkpoint.model_checkpoint_path.rsplit('-', 1)[1])\n",
    "\n",
    "    X, Y = inputs()\n",
    "\n",
    "    total_loss = loss(X, Y)\n",
    "    train_op = train(total_loss)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # actual training loop\n",
    "    training_steps = 1000\n",
    "    print(initial_step, initial_step + training_steps)\n",
    "    for step in range(initial_step, initial_step + training_steps):\n",
    "        sess.run([train_op])\n",
    "        # for debugging and learning purposes, see how the loss gets decremented thru training steps\n",
    "        if step % 10 == 0:\n",
    "            print(\"loss: \", sess.run([total_loss]))\n",
    "    \n",
    "    evaluate(sess, X, Y)\n",
    "\n",
    "    saver.save(sess, 'ml-basics-model', global_step=initial_step + training_steps)\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
